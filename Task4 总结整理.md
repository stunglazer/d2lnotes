# Task4 æ€»ç»“æ•´ç†
## å«æ³¨æ„åŠ›æœºåˆ¶çš„ç¼–ç å™¨â€”è§£ç å™¨

æˆ‘ä»¬å°†ä½¿ç”¨å«æ³¨æ„åŠ›æœºåˆ¶çš„ç¼–ç å™¨â€”è§£ç å™¨æ¥å°†ä¸€æ®µç®€çŸ­çš„æ³•è¯­ç¿»è¯‘æˆè‹±è¯­ã€‚ä¸‹é¢æˆ‘ä»¬æ¥ä»‹ç»æ¨¡å‹çš„å®ç°ã€‚

### ç¼–ç å™¨

åœ¨ç¼–ç å™¨ä¸­ï¼Œæˆ‘ä»¬å°†è¾“å…¥è¯­è¨€çš„è¯ç´¢å¼•é€šè¿‡è¯åµŒå…¥å±‚å¾—åˆ°è¯çš„è¡¨å¾ï¼Œç„¶åè¾“å…¥åˆ°ä¸€ä¸ªå¤šå±‚é—¨æ§å¾ªç¯å•å…ƒä¸­ã€‚æ­£å¦‚æˆ‘ä»¬åœ¨[â€œå¾ªç¯ç¥ç»ç½‘ç»œçš„ç®€æ´å®ç°â€](../chapter_recurrent-neural-networks/rnn-gluon.md)ä¸€èŠ‚æåˆ°çš„ï¼ŒGluonçš„`rnn.GRU`å®ä¾‹åœ¨å‰å‘è®¡ç®—åä¹Ÿä¼šåˆ†åˆ«è¿”å›è¾“å‡ºå’Œæœ€ç»ˆæ—¶é—´æ­¥çš„å¤šå±‚éšè—çŠ¶æ€ã€‚å…¶ä¸­çš„è¾“å‡ºæŒ‡çš„æ˜¯æœ€åä¸€å±‚çš„éšè—å±‚åœ¨å„ä¸ªæ—¶é—´æ­¥çš„éšè—çŠ¶æ€ï¼Œå¹¶ä¸æ¶‰åŠè¾“å‡ºå±‚è®¡ç®—ã€‚æ³¨æ„åŠ›æœºåˆ¶å°†è¿™äº›è¾“å‡ºä½œä¸ºé”®é¡¹å’Œå€¼é¡¹ã€‚

```{.python .input  n=165}
class Encoder(nn.Block):
    def __init__(self, vocab_size, embed_size, num_hiddens, num_layers,
                 drop_prob=0, **kwargs):
        super(Encoder, self).__init__(**kwargs)
        self.embedding = nn.Embedding(vocab_size, embed_size)
        self.rnn = rnn.GRU(num_hiddens, num_layers, dropout=drop_prob)

    def forward(self, inputs, state):
        # è¾“å…¥å½¢çŠ¶æ˜¯(æ‰¹é‡å¤§å°, æ—¶é—´æ­¥æ•°)ã€‚å°†è¾“å‡ºäº’æ¢æ ·æœ¬ç»´å’Œæ—¶é—´æ­¥ç»´
        embedding = self.embedding(inputs).swapaxes(0, 1)
        return self.rnn(embedding, state)

    def begin_state(self, *args, **kwargs):
        return self.rnn.begin_state(*args, **kwargs)
```

ä¸‹é¢æˆ‘ä»¬æ¥åˆ›å»ºä¸€ä¸ªæ‰¹é‡å¤§å°ä¸º4ã€æ—¶é—´æ­¥æ•°ä¸º7çš„å°æ‰¹é‡åºåˆ—è¾“å…¥ã€‚è®¾é—¨æ§å¾ªç¯å•å…ƒçš„éšè—å±‚ä¸ªæ•°ä¸º2ï¼Œéšè—å•å…ƒä¸ªæ•°ä¸º16ã€‚ç¼–ç å™¨å¯¹è¯¥è¾“å…¥æ‰§è¡Œå‰å‘è®¡ç®—åè¿”å›çš„è¾“å‡ºå½¢çŠ¶ä¸º(æ—¶é—´æ­¥æ•°, æ‰¹é‡å¤§å°, éšè—å•å…ƒä¸ªæ•°)ã€‚é—¨æ§å¾ªç¯å•å…ƒåœ¨æœ€ç»ˆæ—¶é—´æ­¥çš„å¤šå±‚éšè—çŠ¶æ€çš„å½¢çŠ¶ä¸º(éšè—å±‚ä¸ªæ•°, æ‰¹é‡å¤§å°, éšè—å•å…ƒä¸ªæ•°)ã€‚å¯¹äºé—¨æ§å¾ªç¯å•å…ƒæ¥è¯´ï¼Œ`state`åˆ—è¡¨ä¸­åªå«ä¸€ä¸ªå…ƒç´ ï¼Œå³éšè—çŠ¶æ€ï¼›å¦‚æœä½¿ç”¨é•¿çŸ­æœŸè®°å¿†ï¼Œ`state`åˆ—è¡¨ä¸­è¿˜å°†åŒ…å«å¦ä¸€ä¸ªå…ƒç´ ï¼Œå³è®°å¿†ç»†èƒã€‚

```{.python .input  n=166}
encoder = Encoder(vocab_size=10, embed_size=8, num_hiddens=16, num_layers=2)
encoder.initialize()
output, state = encoder(nd.zeros((4, 7)), encoder.begin_state(batch_size=4))
output.shape, state[0].shape
```

## æ³¨æ„åŠ›æœºåˆ¶

åœ¨ä»‹ç»å¦‚ä½•å®ç°æ³¨æ„åŠ›æœºåˆ¶çš„çŸ¢é‡åŒ–è®¡ç®—ä¹‹å‰ï¼Œæˆ‘ä»¬å…ˆäº†è§£ä¸€ä¸‹`Dense`å®ä¾‹çš„`flatten`é€‰é¡¹ã€‚å½“è¾“å…¥çš„ç»´åº¦å¤§äº2æ—¶ï¼Œé»˜è®¤æƒ…å†µä¸‹ï¼Œ`Dense`å®ä¾‹ä¼šå°†é™¤äº†ç¬¬ä¸€ç»´ï¼ˆæ ·æœ¬ç»´ï¼‰ä»¥å¤–çš„ç»´åº¦å‡è§†ä½œéœ€è¦ä»¿å°„å˜æ¢çš„ç‰¹å¾ç»´ï¼Œå¹¶å°†è¾“å…¥è‡ªåŠ¨è½¬æˆè¡Œä¸ºæ ·æœ¬ã€åˆ—ä¸ºç‰¹å¾çš„äºŒç»´çŸ©é˜µã€‚è®¡ç®—åï¼Œè¾“å‡ºçŸ©é˜µçš„å½¢çŠ¶ä¸º(æ ·æœ¬æ•°, è¾“å‡ºä¸ªæ•°)ã€‚å¦‚æœæˆ‘ä»¬å¸Œæœ›å…¨è¿æ¥å±‚åªå¯¹è¾“å…¥çš„æœ€åä¸€ç»´åšä»¿å°„å˜æ¢ï¼Œè€Œä¿æŒå…¶ä»–ç»´åº¦ä¸Šçš„å½¢çŠ¶ä¸å˜ï¼Œä¾¿éœ€è¦å°†`Dense`å®ä¾‹çš„`flatten`é€‰é¡¹è®¾ä¸º`False`ã€‚åœ¨ä¸‹é¢ä¾‹å­ä¸­ï¼Œå…¨è¿æ¥å±‚åªå¯¹è¾“å…¥çš„æœ€åä¸€ç»´åšä»¿å°„å˜æ¢ï¼Œå› æ­¤è¾“å‡ºå½¢çŠ¶ä¸­åªæœ‰æœ€åä¸€ç»´å˜ä¸ºå…¨è¿æ¥å±‚çš„è¾“å‡ºä¸ªæ•°2ã€‚



```{.python .input}
dense = nn.Dense(2, flatten=False)
dense.initialize()
dense(nd.zeros((3, 5, 7))).shape
```

æˆ‘ä»¬å°†å®ç°[â€œæ³¨æ„åŠ›æœºåˆ¶â€](./attention.md)ä¸€èŠ‚ä¸­å®šä¹‰çš„å‡½æ•°$a$ï¼šå°†è¾“å…¥è¿ç»“åé€šè¿‡å«å•éšè—å±‚çš„å¤šå±‚æ„ŸçŸ¥æœºå˜æ¢ã€‚å…¶ä¸­éšè—å±‚çš„è¾“å…¥æ˜¯è§£ç å™¨çš„éšè—çŠ¶æ€ä¸ç¼–ç å™¨åœ¨æ‰€æœ‰æ—¶é—´æ­¥ä¸Šéšè—çŠ¶æ€çš„ä¸€ä¸€è¿ç»“ï¼Œä¸”ä½¿ç”¨tanhå‡½æ•°ä½œä¸ºæ¿€æ´»å‡½æ•°ã€‚è¾“å‡ºå±‚çš„è¾“å‡ºä¸ªæ•°ä¸º1ã€‚ä¸¤ä¸ª`Dense`å®ä¾‹å‡ä¸ä½¿ç”¨åå·®ï¼Œä¸”è®¾`flatten=False`ã€‚å…¶ä¸­å‡½æ•°$a$å®šä¹‰é‡Œå‘é‡$\boldsymbol{v}$çš„é•¿åº¦æ˜¯ä¸€ä¸ªè¶…å‚æ•°ï¼Œå³`attention_size`ã€‚

```{.python .input  n=167}
def attention_model(attention_size):
    model = nn.Sequential()
    model.add(nn.Dense(attention_size, activation='tanh', use_bias=False,
                       flatten=False),
              nn.Dense(1, use_bias=False, flatten=False))
    return model
```

æ³¨æ„åŠ›æœºåˆ¶çš„è¾“å…¥åŒ…æ‹¬æŸ¥è¯¢é¡¹ã€é”®é¡¹å’Œå€¼é¡¹ã€‚è®¾ç¼–ç å™¨å’Œè§£ç å™¨çš„éšè—å•å…ƒä¸ªæ•°ç›¸åŒã€‚è¿™é‡Œçš„æŸ¥è¯¢é¡¹ä¸ºè§£ç å™¨åœ¨ä¸Šä¸€æ—¶é—´æ­¥çš„éšè—çŠ¶æ€ï¼Œå½¢çŠ¶ä¸º(æ‰¹é‡å¤§å°, éšè—å•å…ƒä¸ªæ•°)ï¼›é”®é¡¹å’Œå€¼é¡¹å‡ä¸ºç¼–ç å™¨åœ¨æ‰€æœ‰æ—¶é—´æ­¥çš„éšè—çŠ¶æ€ï¼Œå½¢çŠ¶ä¸º(æ—¶é—´æ­¥æ•°, æ‰¹é‡å¤§å°, éšè—å•å…ƒä¸ªæ•°)ã€‚æ³¨æ„åŠ›æœºåˆ¶è¿”å›å½“å‰æ—¶é—´æ­¥çš„èƒŒæ™¯å˜é‡ï¼Œå½¢çŠ¶ä¸º(æ‰¹é‡å¤§å°, éšè—å•å…ƒä¸ªæ•°)ã€‚



```{.python .input  n=168}
def attention_forward(model, enc_states, dec_state):
    # å°†è§£ç å™¨éšè—çŠ¶æ€å¹¿æ’­åˆ°å’Œç¼–ç å™¨éšè—çŠ¶æ€å½¢çŠ¶ç›¸åŒåè¿›è¡Œè¿ç»“
    dec_states = nd.broadcast_axis(
        dec_state.expand_dims(0), axis=0, size=enc_states.shape[0])
    enc_and_dec_states = nd.concat(enc_states, dec_states, dim=2)
    e = model(enc_and_dec_states)  # å½¢çŠ¶ä¸º(æ—¶é—´æ­¥æ•°, æ‰¹é‡å¤§å°, 1)
    alpha = nd.softmax(e, axis=0)  # åœ¨æ—¶é—´æ­¥ç»´åº¦åšsoftmaxè¿ç®—
    return (alpha * enc_states).sum(axis=0)  # è¿”å›èƒŒæ™¯å˜é‡
```

åœ¨ä¸‹é¢çš„ä¾‹å­ä¸­ï¼Œç¼–ç å™¨çš„æ—¶é—´æ­¥æ•°ä¸º10ï¼Œæ‰¹é‡å¤§å°ä¸º4ï¼Œç¼–ç å™¨å’Œè§£ç å™¨çš„éšè—å•å…ƒä¸ªæ•°å‡ä¸º8ã€‚æ³¨æ„åŠ›æœºåˆ¶è¿”å›ä¸€ä¸ªå°æ‰¹é‡çš„èƒŒæ™¯å‘é‡ï¼Œæ¯ä¸ªèƒŒæ™¯å‘é‡çš„é•¿åº¦ç­‰äºç¼–ç å™¨çš„éšè—å•å…ƒä¸ªæ•°ã€‚å› æ­¤è¾“å‡ºçš„å½¢çŠ¶ä¸º(4, 8)ã€‚

```{.python .input  n=169}
seq_len, batch_size, num_hiddens = 10, 4, 8
model = attention_model(10)
model.initialize()
enc_states = nd.zeros((seq_len, batch_size, num_hiddens))
dec_state = nd.zeros((batch_size, num_hiddens))
attention_forward(model, enc_states, dec_state).shape
```

### å«æ³¨æ„åŠ›æœºåˆ¶çš„è§£ç å™¨

æˆ‘ä»¬ç›´æ¥å°†ç¼–ç å™¨åœ¨æœ€ç»ˆæ—¶é—´æ­¥çš„éšè—çŠ¶æ€ä½œä¸ºè§£ç å™¨çš„åˆå§‹éšè—çŠ¶æ€ã€‚è¿™è¦æ±‚ç¼–ç å™¨å’Œè§£ç å™¨çš„å¾ªç¯ç¥ç»ç½‘ç»œä½¿ç”¨ç›¸åŒçš„éšè—å±‚ä¸ªæ•°å’Œéšè—å•å…ƒä¸ªæ•°ã€‚

åœ¨è§£ç å™¨çš„å‰å‘è®¡ç®—ä¸­ï¼Œæˆ‘ä»¬å…ˆé€šè¿‡åˆšåˆšä»‹ç»çš„æ³¨æ„åŠ›æœºåˆ¶è®¡ç®—å¾—åˆ°å½“å‰æ—¶é—´æ­¥çš„èƒŒæ™¯å‘é‡ã€‚ç”±äºè§£ç å™¨çš„è¾“å…¥æ¥è‡ªè¾“å‡ºè¯­è¨€çš„è¯ç´¢å¼•ï¼Œæˆ‘ä»¬å°†è¾“å…¥é€šè¿‡è¯åµŒå…¥å±‚å¾—åˆ°è¡¨å¾ï¼Œç„¶åå’ŒèƒŒæ™¯å‘é‡åœ¨ç‰¹å¾ç»´è¿ç»“ã€‚æˆ‘ä»¬å°†è¿ç»“åçš„ç»“æœä¸ä¸Šä¸€æ—¶é—´æ­¥çš„éšè—çŠ¶æ€é€šè¿‡é—¨æ§å¾ªç¯å•å…ƒè®¡ç®—å‡ºå½“å‰æ—¶é—´æ­¥çš„è¾“å‡ºä¸éšè—çŠ¶æ€ã€‚æœ€åï¼Œæˆ‘ä»¬å°†è¾“å‡ºé€šè¿‡å…¨è¿æ¥å±‚å˜æ¢ä¸ºæœ‰å…³å„ä¸ªè¾“å‡ºè¯çš„é¢„æµ‹ï¼Œå½¢çŠ¶ä¸º(æ‰¹é‡å¤§å°, è¾“å‡ºè¯å…¸å¤§å°)ã€‚

```{.python .input  n=170}
class Decoder(nn.Block):
    def __init__(self, vocab_size, embed_size, num_hiddens, num_layers,
                 attention_size, drop_prob=0, **kwargs):
        super(Decoder, self).__init__(**kwargs)
        self.embedding = nn.Embedding(vocab_size, embed_size)
        self.attention = attention_model(attention_size)
        self.rnn = rnn.GRU(num_hiddens, num_layers, dropout=drop_prob)
        self.out = nn.Dense(vocab_size, flatten=False)

    def forward(self, cur_input, state, enc_states):
        # ä½¿ç”¨æ³¨æ„åŠ›æœºåˆ¶è®¡ç®—èƒŒæ™¯å‘é‡
        c = attention_forward(self.attention, enc_states, state[0][-1])
        # å°†åµŒå…¥åçš„è¾“å…¥å’ŒèƒŒæ™¯å‘é‡åœ¨ç‰¹å¾ç»´è¿ç»“
        input_and_c = nd.concat(self.embedding(cur_input), c, dim=1)
        # ä¸ºè¾“å…¥å’ŒèƒŒæ™¯å‘é‡çš„è¿ç»“å¢åŠ æ—¶é—´æ­¥ç»´ï¼Œæ—¶é—´æ­¥ä¸ªæ•°ä¸º1
        output, state = self.rnn(input_and_c.expand_dims(0), state)
        # ç§»é™¤æ—¶é—´æ­¥ç»´ï¼Œè¾“å‡ºå½¢çŠ¶ä¸º(æ‰¹é‡å¤§å°, è¾“å‡ºè¯å…¸å¤§å°)
        output = self.out(output).squeeze(axis=0)
        return output, state

    def begin_state(self, enc_state):
        # ç›´æ¥å°†ç¼–ç å™¨æœ€ç»ˆæ—¶é—´æ­¥çš„éšè—çŠ¶æ€ä½œä¸ºè§£ç å™¨çš„åˆå§‹éšè—çŠ¶æ€
        return enc_state
```
### ç»ƒä¹ æ³¨è§£
ä¸å±äºEncoder-Decoderåº”ç”¨çš„æ˜¯ï¼šè¯­éŸ³è¯†åˆ«ä»»åŠ¡

- Encoder-Decoderå¸¸åº”ç”¨äºè¾“å…¥åºåˆ—å’Œè¾“å‡ºåºåˆ—çš„é•¿åº¦æ˜¯å¯å˜çš„ï¼Œå¦‚é€‰é¡¹ä¸€äºŒå››ï¼Œè€Œåˆ†ç±»é—®é¢˜çš„è¾“å‡ºæ˜¯å›ºå®šçš„ç±»åˆ«ï¼Œä¸éœ€è¦ä½¿ç”¨Encoder-Decoder

### æ³¨æ„åŠ›æœºåˆ¶

åœ¨â€œç¼–ç å™¨â€”è§£ç å™¨ï¼ˆseq2seqï¼‰â€â¼€èŠ‚â¾¥ï¼Œè§£ç å™¨åœ¨å„ä¸ªæ—¶é—´æ­¥ä¾èµ–ç›¸åŒçš„èƒŒæ™¯å˜é‡ï¼ˆcontext vectorï¼‰æ¥è·å–è¾“â¼Šåºåˆ—ä¿¡æ¯ã€‚å½“ç¼–ç å™¨ä¸ºå¾ªç¯ç¥ç»â½¹ç»œæ—¶ï¼ŒèƒŒæ™¯å˜é‡æ¥â¾ƒå®ƒæœ€ç»ˆæ—¶é—´æ­¥çš„éšè—çŠ¶æ€ã€‚å°†æºåºåˆ—è¾“å…¥ä¿¡æ¯ä»¥å¾ªç¯å•ä½çŠ¶æ€ç¼–ç ï¼Œç„¶åå°†å…¶ä¼ é€’ç»™è§£ç å™¨ä»¥ç”Ÿæˆç›®æ ‡åºåˆ—ã€‚ç„¶è€Œè¿™ç§ç»“æ„å­˜åœ¨ç€é—®é¢˜ï¼Œå°¤å…¶æ˜¯RNNæœºåˆ¶å®é™…ä¸­å­˜åœ¨é•¿ç¨‹æ¢¯åº¦æ¶ˆå¤±çš„é—®é¢˜ï¼Œå¯¹äºè¾ƒé•¿çš„å¥å­ï¼Œæˆ‘ä»¬å¾ˆéš¾å¯„å¸Œæœ›äºå°†è¾“å…¥çš„åºåˆ—è½¬åŒ–ä¸ºå®šé•¿çš„å‘é‡è€Œä¿å­˜æ‰€æœ‰çš„æœ‰æ•ˆä¿¡æ¯ï¼Œæ‰€ä»¥éšç€æ‰€éœ€ç¿»è¯‘å¥å­çš„é•¿åº¦çš„å¢åŠ ï¼Œè¿™ç§ç»“æ„çš„æ•ˆæœä¼šæ˜¾è‘—ä¸‹é™ã€‚

ä¸æ­¤åŒæ—¶ï¼Œè§£ç çš„ç›®æ ‡è¯è¯­å¯èƒ½åªä¸åŸè¾“å…¥çš„éƒ¨åˆ†è¯è¯­æœ‰å…³ï¼Œè€Œå¹¶ä¸æ˜¯ä¸æ‰€æœ‰çš„è¾“å…¥æœ‰å…³ã€‚ä¾‹å¦‚ï¼Œå½“æŠŠâ€œHello worldâ€ç¿»è¯‘æˆâ€œBonjour le mondeâ€æ—¶ï¼Œâ€œHelloâ€æ˜ å°„æˆâ€œBonjourâ€ï¼Œâ€œworldâ€æ˜ å°„æˆâ€œmondeâ€ã€‚åœ¨seq2seqæ¨¡å‹ä¸­ï¼Œè§£ç å™¨åªèƒ½éšå¼åœ°ä»ç¼–ç å™¨çš„æœ€ç»ˆçŠ¶æ€ä¸­é€‰æ‹©ç›¸åº”çš„ä¿¡æ¯ã€‚ç„¶è€Œï¼Œæ³¨æ„åŠ›æœºåˆ¶å¯ä»¥å°†è¿™ç§é€‰æ‹©è¿‡ç¨‹æ˜¾å¼åœ°å»ºæ¨¡ã€‚

![Image Name](https://cdn.kesci.com/upload/image/q5km4dwgf9.PNG?imageView2/0/w/960/h/960)

#### æ³¨æ„åŠ›æœºåˆ¶æ¡†æ¶

Attention æ˜¯ä¸€ç§é€šç”¨çš„å¸¦æƒæ± åŒ–æ–¹æ³•ï¼Œè¾“å…¥ç”±ä¸¤éƒ¨åˆ†æ„æˆï¼šè¯¢é—®ï¼ˆqueryï¼‰å’Œé”®å€¼å¯¹ï¼ˆkey-value pairsï¼‰ã€‚$ğ¤_ğ‘–âˆˆâ„^{ğ‘‘_ğ‘˜}, ğ¯_ğ‘–âˆˆâ„^{ğ‘‘_ğ‘£}$. Query  $ğªâˆˆâ„^{ğ‘‘_ğ‘}$ , attention layerå¾—åˆ°è¾“å‡ºä¸valueçš„ç»´åº¦ä¸€è‡´ $ğ¨âˆˆâ„^{ğ‘‘_ğ‘£}$. å¯¹äºä¸€ä¸ªqueryæ¥è¯´ï¼Œattention layer ä¼šä¸æ¯ä¸€ä¸ªkeyè®¡ç®—æ³¨æ„åŠ›åˆ†æ•°å¹¶è¿›è¡Œæƒé‡çš„å½’ä¸€åŒ–ï¼Œè¾“å‡ºçš„å‘é‡$o$åˆ™æ˜¯valueçš„åŠ æƒæ±‚å’Œï¼Œè€Œæ¯ä¸ªkeyè®¡ç®—çš„æƒé‡ä¸valueä¸€ä¸€å¯¹åº”ã€‚

ä¸ºäº†è®¡ç®—è¾“å‡ºï¼Œæˆ‘ä»¬é¦–å…ˆå‡è®¾æœ‰ä¸€ä¸ªå‡½æ•°$\alpha$ ç”¨äºè®¡ç®—queryå’Œkeyçš„ç›¸ä¼¼æ€§ï¼Œç„¶åå¯ä»¥è®¡ç®—æ‰€æœ‰çš„ attention scores $a_1, \ldots, a_n$ by


$$
a_i = \alpha(\mathbf q, \mathbf k_i).
$$


æˆ‘ä»¬ä½¿ç”¨ softmaxå‡½æ•° è·å¾—æ³¨æ„åŠ›æƒé‡ï¼š


$$
b_1, \ldots, b_n = \textrm{softmax}(a_1, \ldots, a_n).
$$


æœ€ç»ˆçš„è¾“å‡ºå°±æ˜¯valueçš„åŠ æƒæ±‚å’Œï¼š


$$
\mathbf o = \sum_{i=1}^n b_i \mathbf v_i.
$$


![Image Name](https://cdn.kesci.com/upload/image/q5km4ooyu2.PNG?imageView2/0/w/960/h/960)
##### ç‚¹ç§¯æ³¨æ„åŠ›

The dot product å‡è®¾queryå’Œkeysæœ‰ç›¸åŒçš„ç»´åº¦, å³ $\forall i, ğª,ğ¤_ğ‘– âˆˆ â„_ğ‘‘ $. é€šè¿‡è®¡ç®—queryå’Œkeyè½¬ç½®çš„ä¹˜ç§¯æ¥è®¡ç®—attention score,é€šå¸¸è¿˜ä¼šé™¤å» $\sqrt{d}$ å‡å°‘è®¡ç®—å‡ºæ¥çš„scoreå¯¹ç»´åº¦ğ‘‘çš„ä¾èµ–æ€§ï¼Œå¦‚ä¸‹


$$
ğ›¼(ğª,ğ¤)=âŸ¨ğª,ğ¤âŸ©/ \sqrt{d} 
$$

å‡è®¾ $ ğâˆˆâ„^{ğ‘šÃ—ğ‘‘}$ æœ‰ $m$ ä¸ªqueryï¼Œ$ğŠâˆˆâ„^{ğ‘›Ã—ğ‘‘}$ æœ‰ $n$ ä¸ªkeys. æˆ‘ä»¬å¯ä»¥é€šè¿‡çŸ©é˜µè¿ç®—çš„æ–¹å¼è®¡ç®—æ‰€æœ‰ $mn$ ä¸ªscoreï¼š


$$
ğ›¼(ğ,ğŠ)=ğğŠ^ğ‘‡/\sqrt{d}
$$

ç°åœ¨è®©æˆ‘ä»¬å®ç°è¿™ä¸ªå±‚ï¼Œå®ƒæ”¯æŒä¸€æ‰¹æŸ¥è¯¢å’Œé”®å€¼å¯¹ã€‚æ­¤å¤–ï¼Œå®ƒæ”¯æŒä½œä¸ºæ­£åˆ™åŒ–éšæœºåˆ é™¤ä¸€äº›æ³¨æ„åŠ›æƒé‡.

##### å¤šå±‚æ„ŸçŸ¥æœºæ³¨æ„åŠ›

åœ¨å¤šå±‚æ„ŸçŸ¥å™¨ä¸­ï¼Œæˆ‘ä»¬é¦–å…ˆå°† query and keys æŠ•å½±åˆ°  $â„^â„$ .ä¸ºäº†æ›´å…·ä½“ï¼Œæˆ‘ä»¬å°†å¯ä»¥å­¦ä¹ çš„å‚æ•°åšå¦‚ä¸‹æ˜ å°„ 
$ğ–_ğ‘˜âˆˆâ„^{â„Ã—ğ‘‘_ğ‘˜}$ ,  $ğ–_ğ‘âˆˆâ„^{â„Ã—ğ‘‘_ğ‘}$ , and  $ğ¯âˆˆâ„^h$ . å°†scoreå‡½æ•°å®šä¹‰
$$
ğ›¼(ğ¤,ğª)=ğ¯^ğ‘‡tanh(ğ–_ğ‘˜ğ¤+ğ–_ğ‘ğª)
$$
. 
ç„¶åå°†key å’Œ value åœ¨ç‰¹å¾çš„ç»´åº¦ä¸Šåˆå¹¶ï¼ˆconcatenateï¼‰ï¼Œç„¶åé€è‡³ a single hidden layer perceptron è¿™å±‚ä¸­ hidden layer ä¸º  â„  and è¾“å‡ºçš„sizeä¸º 1 .éšå±‚æ¿€æ´»å‡½æ•°ä¸ºtanhï¼Œæ— åç½®.
#### å¼•å…¥æ³¨æ„åŠ›æœºåˆ¶çš„Seq2seqæ¨¡å‹

æœ¬èŠ‚ä¸­å°†æ³¨æ„æœºåˆ¶æ·»åŠ åˆ°sequence to sequence æ¨¡å‹ä¸­ï¼Œä»¥æ˜¾å¼åœ°ä½¿ç”¨æƒé‡èšåˆstatesã€‚ä¸‹å›¾å±•ç¤ºencoding å’Œdecodingçš„æ¨¡å‹ç»“æ„ï¼Œåœ¨æ—¶é—´æ­¥ä¸ºtçš„æ—¶å€™ã€‚æ­¤åˆ»attention layerä¿å­˜ç€encoderingçœ‹åˆ°çš„æ‰€æœ‰ä¿¡æ¯â€”â€”å³encodingçš„æ¯ä¸€æ­¥è¾“å‡ºã€‚åœ¨decodingé˜¶æ®µï¼Œè§£ç å™¨çš„$t$æ—¶åˆ»çš„éšè—çŠ¶æ€è¢«å½“ä½œqueryï¼Œencoderçš„æ¯ä¸ªæ—¶é—´æ­¥çš„hidden statesä½œä¸ºkeyå’Œvalueè¿›è¡Œattentionèšåˆ. Attetion modelçš„è¾“å‡ºå½“ä½œæˆä¸Šä¸‹æ–‡ä¿¡æ¯context vectorï¼Œå¹¶ä¸è§£ç å™¨è¾“å…¥$D_t$æ‹¼æ¥èµ·æ¥ä¸€èµ·é€åˆ°è§£ç å™¨ï¼š

![Image Name](https://cdn.kesci.com/upload/image/q5km7o8z93.PNG?imageView2/0/w/800/h/800)

$$
Fig1å…·æœ‰æ³¨æ„æœºåˆ¶çš„seq-to-seqæ¨¡å‹è§£ç çš„ç¬¬äºŒæ­¥
$$


ä¸‹å›¾å±•ç¤ºäº†seq2seqæœºåˆ¶çš„æ‰€ä»¥å±‚çš„å…³ç³»ï¼Œä¸‹é¢å±•ç¤ºäº†encoderå’Œdecoderçš„layerç»“æ„

![Image Name](https://cdn.kesci.com/upload/image/q5km8dihlr.PNG?imageView2/0/w/800/h/800)

$$
Fig2å…·æœ‰æ³¨æ„æœºåˆ¶çš„seq-to-seqæ¨¡å‹ä¸­å±‚ç»“æ„
$$

#### è§£ç å™¨

   ç”±äºå¸¦æœ‰æ³¨æ„æœºåˆ¶çš„seq2seqçš„ç¼–ç å™¨ä¸ä¹‹å‰ç« èŠ‚ä¸­çš„Seq2SeqEncoderç›¸åŒï¼Œæ‰€ä»¥åœ¨æ­¤å¤„æˆ‘ä»¬åªå…³æ³¨è§£ç å™¨ã€‚æˆ‘ä»¬æ·»åŠ äº†ä¸€ä¸ªMLPæ³¨æ„å±‚(MLPAttention)ï¼Œå®ƒçš„éšè—å¤§å°ä¸è§£ç å™¨ä¸­çš„LSTMå±‚ç›¸åŒã€‚ç„¶åæˆ‘ä»¬é€šè¿‡ä»ç¼–ç å™¨ä¼ é€’ä¸‰ä¸ªå‚æ•°æ¥åˆå§‹åŒ–è§£ç å™¨çš„çŠ¶æ€:

- the encoder outputs of all timestepsï¼šencoderè¾“å‡ºçš„å„ä¸ªçŠ¶æ€ï¼Œè¢«ç”¨äºattetion layerçš„memoryéƒ¨åˆ†ï¼Œæœ‰ç›¸åŒçš„keyå’Œvalues


- the hidden state of the encoderâ€™s final timestepï¼šç¼–ç å™¨æœ€åä¸€ä¸ªæ—¶é—´æ­¥çš„éšè—çŠ¶æ€ï¼Œè¢«ç”¨äºåˆå§‹åŒ–decoder çš„hidden state


- the encoder valid length: ç¼–ç å™¨çš„æœ‰æ•ˆé•¿åº¦ï¼Œå€Ÿæ­¤ï¼Œæ³¨æ„å±‚ä¸ä¼šè€ƒè™‘ç¼–ç å™¨è¾“å‡ºä¸­çš„å¡«å……æ ‡è®°ï¼ˆPaddingsï¼‰


   åœ¨è§£ç çš„æ¯ä¸ªæ—¶é—´æ­¥ï¼Œæˆ‘ä»¬ä½¿ç”¨è§£ç å™¨çš„æœ€åä¸€ä¸ªRNNå±‚çš„è¾“å‡ºä½œä¸ºæ³¨æ„å±‚çš„queryã€‚ç„¶åï¼Œå°†æ³¨æ„åŠ›æ¨¡å‹çš„è¾“å‡ºä¸è¾“å…¥åµŒå…¥å‘é‡è¿æ¥èµ·æ¥ï¼Œè¾“å…¥åˆ°RNNå±‚ã€‚è™½ç„¶RNNå±‚éšè—çŠ¶æ€ä¹ŸåŒ…å«æ¥è‡ªè§£ç å™¨çš„å†å²ä¿¡æ¯ï¼Œä½†æ˜¯attention modelçš„è¾“å‡ºæ˜¾å¼åœ°é€‰æ‹©äº†enc_valid_lenä»¥å†…çš„ç¼–ç å™¨è¾“å‡ºï¼Œè¿™æ ·attentionæœºåˆ¶å°±ä¼šå°½å¯èƒ½æ’é™¤å…¶ä»–ä¸ç›¸å…³çš„ä¿¡æ¯ã€‚

*<u>æ³¨æ„åŠ›æœºåˆ¶æœ¬èº«æœ‰é«˜æ•ˆçš„å¹¶è¡Œæ€§ï¼Œä½†å¼•å…¥æ³¨æ„åŠ›å¹¶ä¸èƒ½æ”¹å˜seq2seqå†…éƒ¨RNNçš„è¿­ä»£æœºåˆ¶ï¼Œå› æ­¤æ— æ³•åŠ é€Ÿã€‚</u>*
## Transformer

åœ¨ä¹‹å‰çš„ç« èŠ‚ä¸­ï¼Œæˆ‘ä»¬å·²ç»ä»‹ç»äº†ä¸»æµçš„ç¥ç»ç½‘ç»œæ¶æ„å¦‚å·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNsï¼‰å’Œå¾ªç¯ç¥ç»ç½‘ç»œï¼ˆRNNsï¼‰ã€‚è®©æˆ‘ä»¬è¿›è¡Œä¸€äº›å›é¡¾ï¼š

- CNNs æ˜“äºå¹¶è¡ŒåŒ–ï¼Œå´ä¸é€‚åˆæ•æ‰å˜é•¿åºåˆ—å†…çš„ä¾èµ–å…³ç³»ã€‚
- RNNs é€‚åˆæ•æ‰é•¿è·ç¦»å˜é•¿åºåˆ—çš„ä¾èµ–ï¼Œä½†æ˜¯å´éš¾ä»¥å®ç°å¹¶è¡ŒåŒ–å¤„ç†åºåˆ—ã€‚

ä¸ºäº†æ•´åˆCNNå’ŒRNNçš„ä¼˜åŠ¿ï¼Œ[\[Vaswani et al., 2017\]](https://d2l.ai/chapter_references/zreferences.html#vaswani-shazeer-parmar-ea-2017) åˆ›æ–°æ€§åœ°ä½¿ç”¨æ³¨æ„åŠ›æœºåˆ¶è®¾è®¡äº†Transformeræ¨¡å‹ã€‚è¯¥æ¨¡å‹åˆ©ç”¨attentionæœºåˆ¶å®ç°äº†å¹¶è¡ŒåŒ–æ•æ‰åºåˆ—ä¾èµ–ï¼Œå¹¶ä¸”åŒæ—¶å¤„ç†åºåˆ—çš„æ¯ä¸ªä½ç½®çš„tokensï¼Œä¸Šè¿°ä¼˜åŠ¿ä½¿å¾—Transformeræ¨¡å‹åœ¨æ€§èƒ½ä¼˜å¼‚çš„åŒæ—¶å¤§å¤§å‡å°‘äº†è®­ç»ƒæ—¶é—´ã€‚

å›¾10.3.1å±•ç¤ºäº†Transformeræ¨¡å‹çš„æ¶æ„ï¼Œä¸9.7èŠ‚çš„seq2seqæ¨¡å‹ç›¸ä¼¼ï¼ŒTransformeråŒæ ·åŸºäºç¼–ç å™¨-è§£ç å™¨æ¶æ„ï¼Œå…¶åŒºåˆ«ä¸»è¦åœ¨äºä»¥ä¸‹ä¸‰ç‚¹ï¼š

1. Transformer blocksï¼šå°†seq2seqæ¨¡å‹é‡çš„å¾ªç¯ç½‘ç»œæ›¿æ¢ä¸ºäº†Transformer Blocksï¼Œè¯¥æ¨¡å—åŒ…å«ä¸€ä¸ªå¤šå¤´æ³¨æ„åŠ›å±‚ï¼ˆMulti-head Attention Layersï¼‰ä»¥åŠä¸¤ä¸ªposition-wise feed-forward networksï¼ˆFFNï¼‰ã€‚å¯¹äºè§£ç å™¨æ¥è¯´ï¼Œå¦ä¸€ä¸ªå¤šå¤´æ³¨æ„åŠ›å±‚è¢«ç”¨äºæ¥å—ç¼–ç å™¨çš„éšè—çŠ¶æ€ã€‚
2. Add and normï¼šå¤šå¤´æ³¨æ„åŠ›å±‚å’Œå‰é¦ˆç½‘ç»œçš„è¾“å‡ºè¢«é€åˆ°ä¸¤ä¸ªâ€œadd and normâ€å±‚è¿›è¡Œå¤„ç†ï¼Œè¯¥å±‚åŒ…å«æ®‹å·®ç»“æ„ä»¥åŠå±‚å½’ä¸€åŒ–ã€‚
3. Position encodingï¼šç”±äºè‡ªæ³¨æ„åŠ›å±‚å¹¶æ²¡æœ‰åŒºåˆ†å…ƒç´ çš„é¡ºåºï¼Œæ‰€ä»¥ä¸€ä¸ªä½ç½®ç¼–ç å±‚è¢«ç”¨äºå‘åºåˆ—å…ƒç´ é‡Œæ·»åŠ ä½ç½®ä¿¡æ¯ã€‚

![Fig. 10.3.1 The Transformer architecture.](https://cdn.kesci.com/upload/image/q5kpbj2cj5.png?imageView2/0/w/960/h/960)

$$
Fig.10.3.1\ Transformer æ¶æ„.
$$
### å¤šå¤´æ³¨æ„åŠ›å±‚

åœ¨æˆ‘ä»¬è®¨è®ºå¤šå¤´æ³¨æ„åŠ›å±‚ä¹‹å‰ï¼Œå…ˆæ¥è¿…é€Ÿç†è§£ä»¥ä¸‹è‡ªæ³¨æ„åŠ›ï¼ˆself-attentionï¼‰çš„ç»“æ„ã€‚è‡ªæ³¨æ„åŠ›æ¨¡å‹æ˜¯ä¸€ä¸ªæ­£è§„çš„æ³¨æ„åŠ›æ¨¡å‹ï¼Œåºåˆ—çš„æ¯ä¸€ä¸ªå…ƒç´ å¯¹åº”çš„keyï¼Œvalueï¼Œqueryæ˜¯å®Œå…¨ä¸€è‡´çš„ã€‚å¦‚å›¾10.3.2 è‡ªæ³¨æ„åŠ›è¾“å‡ºäº†ä¸€ä¸ªä¸è¾“å…¥é•¿åº¦ç›¸åŒçš„è¡¨å¾åºåˆ—ï¼Œä¸å¾ªç¯ç¥ç»ç½‘ç»œç›¸æ¯”ï¼Œè‡ªæ³¨æ„åŠ›å¯¹æ¯ä¸ªå…ƒç´ è¾“å‡ºçš„è®¡ç®—æ˜¯å¹¶è¡Œçš„ï¼Œæ‰€ä»¥æˆ‘ä»¬å¯ä»¥é«˜æ•ˆçš„å®ç°è¿™ä¸ªæ¨¡å—ã€‚

![Fig. 10.3.2 è‡ªæ³¨æ„åŠ›ç»“æ„](https://cdn.kesci.com/upload/image/q5kpckv38q.png?imageView2/0/w/320/h/320)

$$
Fig.10.3.2\ è‡ªæ³¨æ„åŠ›ç»“æ„
$$


å¤šå¤´æ³¨æ„åŠ›å±‚åŒ…å«$h$ä¸ªå¹¶è¡Œçš„è‡ªæ³¨æ„åŠ›å±‚ï¼Œæ¯ä¸€ä¸ªè¿™ç§å±‚è¢«æˆä¸ºä¸€ä¸ªheadã€‚å¯¹æ¯ä¸ªå¤´æ¥è¯´ï¼Œåœ¨è¿›è¡Œæ³¨æ„åŠ›è®¡ç®—ä¹‹å‰ï¼Œæˆ‘ä»¬ä¼šå°†queryã€keyå’Œvalueç”¨ä¸‰ä¸ªç°è¡Œå±‚è¿›è¡Œæ˜ å°„ï¼Œè¿™$h$ä¸ªæ³¨æ„åŠ›å¤´çš„è¾“å‡ºå°†ä¼šè¢«æ‹¼æ¥ä¹‹åè¾“å…¥æœ€åä¸€ä¸ªçº¿æ€§å±‚è¿›è¡Œæ•´åˆã€‚

![Image Name](https://cdn.kesci.com/upload/image/q5kpcsozid.png?imageView2/0/w/640/h/640)

$$
Fig.10.3.3\ å¤šå¤´æ³¨æ„åŠ›
$$


å‡è®¾queryï¼Œkeyå’Œvalueçš„ç»´åº¦åˆ†åˆ«æ˜¯$d_q$ã€$d_k$å’Œ$d_v$ã€‚é‚£ä¹ˆå¯¹äºæ¯ä¸€ä¸ªå¤´$i=1,\ldots,h$ï¼Œæˆ‘ä»¬å¯ä»¥è®­ç»ƒç›¸åº”çš„æ¨¡å‹æƒé‡$W_q^{(i)} \in \mathbb{R}^{p_q\times d_q}$ã€$W_k^{(i)} \in \mathbb{R}^{p_k\times d_k}$å’Œ$W_v^{(i)} \in \mathbb{R}^{p_v\times d_v}$ï¼Œä»¥å¾—åˆ°æ¯ä¸ªå¤´çš„è¾“å‡ºï¼š


$$
o^{(i)} = attention(W_q^{(i)}q, W_k^{(i)}k, W_v^{(i)}v)
$$


è¿™é‡Œçš„attentionå¯ä»¥æ˜¯ä»»æ„çš„attention functionï¼Œæ¯”å¦‚å‰ä¸€èŠ‚ä»‹ç»çš„dot-product attentionä»¥åŠMLP attentionã€‚ä¹‹åæˆ‘ä»¬å°†æ‰€æœ‰headå¯¹åº”çš„è¾“å‡ºæ‹¼æ¥èµ·æ¥ï¼Œé€å…¥æœ€åä¸€ä¸ªçº¿æ€§å±‚è¿›è¡Œæ•´åˆï¼Œè¿™ä¸ªå±‚çš„æƒé‡å¯ä»¥è¡¨ç¤ºä¸º$W_o\in \mathbb{R}^{d_0 \times hp_v}$


$$
o = W_o[o^{(1)}, \ldots, o^{(h)}]
$$


æ¥ä¸‹æ¥æˆ‘ä»¬å°±å¯ä»¥æ¥å®ç°å¤šå¤´æ³¨æ„åŠ›äº†ï¼Œå‡è®¾æˆ‘ä»¬æœ‰hä¸ªå¤´ï¼Œéšè—å±‚æƒé‡ $hidden\_size = p_q = p_k = p_v$ ä¸queryï¼Œkeyï¼Œvalueçš„ç»´åº¦ä¸€è‡´ã€‚é™¤æ­¤ä¹‹å¤–ï¼Œå› ä¸ºå¤šå¤´æ³¨æ„åŠ›å±‚ä¿æŒè¾“å…¥ä¸è¾“å‡ºå¼ é‡çš„ç»´åº¦ä¸å˜ï¼Œæ‰€ä»¥è¾“å‡ºfeatureçš„ç»´åº¦ä¹Ÿè®¾ç½®ä¸º $d_0 = hidden\_size$ã€‚
### åŸºäºä½ç½®çš„å‰é¦ˆç½‘ç»œ

Transformer æ¨¡å—å¦ä¸€ä¸ªéå¸¸é‡è¦çš„éƒ¨åˆ†å°±æ˜¯åŸºäºä½ç½®çš„å‰é¦ˆç½‘ç»œï¼ˆFFNï¼‰ï¼Œå®ƒæ¥å—ä¸€ä¸ªå½¢çŠ¶ä¸ºï¼ˆbatch_sizeï¼Œseq_length, feature_sizeï¼‰çš„ä¸‰ç»´å¼ é‡ã€‚Position-wise FFNç”±ä¸¤ä¸ªå…¨è¿æ¥å±‚ç»„æˆï¼Œä»–ä»¬ä½œç”¨åœ¨æœ€åä¸€ç»´ä¸Šã€‚å› ä¸ºåºåˆ—çš„æ¯ä¸ªä½ç½®çš„çŠ¶æ€éƒ½ä¼šè¢«å•ç‹¬åœ°æ›´æ–°ï¼Œæ‰€ä»¥æˆ‘ä»¬ç§°ä»–ä¸ºposition-wiseï¼Œè¿™ç­‰æ•ˆäºä¸€ä¸ª1x1çš„å·ç§¯ã€‚
### Add and Norm

é™¤äº†ä¸Šé¢ä¸¤ä¸ªæ¨¡å—ä¹‹å¤–ï¼ŒTransformerè¿˜æœ‰ä¸€ä¸ªé‡è¦çš„ç›¸åŠ å½’ä¸€åŒ–å±‚ï¼Œå®ƒå¯ä»¥å¹³æ»‘åœ°æ•´åˆè¾“å…¥å’Œå…¶ä»–å±‚çš„è¾“å‡ºï¼Œå› æ­¤æˆ‘ä»¬åœ¨æ¯ä¸ªå¤šå¤´æ³¨æ„åŠ›å±‚å’ŒFFNå±‚åé¢éƒ½æ·»åŠ ä¸€ä¸ªå«æ®‹å·®è¿æ¥çš„Layer Normå±‚ã€‚è¿™é‡Œ Layer Norm ä¸7.5å°èŠ‚çš„Batch Normå¾ˆç›¸ä¼¼ï¼Œå”¯ä¸€çš„åŒºåˆ«åœ¨äºBatch Normæ˜¯å¯¹äºbatch sizeè¿™ä¸ªç»´åº¦è¿›è¡Œè®¡ç®—å‡å€¼å’Œæ–¹å·®çš„ï¼Œè€ŒLayer Normåˆ™æ˜¯å¯¹æœ€åä¸€ç»´è¿›è¡Œè®¡ç®—ã€‚å±‚å½’ä¸€åŒ–å¯ä»¥é˜²æ­¢å±‚å†…çš„æ•°å€¼å˜åŒ–è¿‡å¤§ï¼Œä»è€Œæœ‰åˆ©äºåŠ å¿«è®­ç»ƒé€Ÿåº¦å¹¶ä¸”æé«˜æ³›åŒ–æ€§èƒ½ã€‚ [(ref)](https://zhuanlan.zhihu.com/p/54530247)

### ä½ç½®ç¼–ç 

ä¸å¾ªç¯ç¥ç»ç½‘ç»œä¸åŒï¼Œæ— è®ºæ˜¯å¤šå¤´æ³¨æ„åŠ›ç½‘ç»œè¿˜æ˜¯å‰é¦ˆç¥ç»ç½‘ç»œéƒ½æ˜¯ç‹¬ç«‹åœ°å¯¹æ¯ä¸ªä½ç½®çš„å…ƒç´ è¿›è¡Œæ›´æ–°ï¼Œè¿™ç§ç‰¹æ€§å¸®åŠ©æˆ‘ä»¬å®ç°äº†é«˜æ•ˆçš„å¹¶è¡Œï¼Œå´ä¸¢å¤±äº†é‡è¦çš„åºåˆ—é¡ºåºçš„ä¿¡æ¯ã€‚ä¸ºäº†æ›´å¥½çš„æ•æ‰åºåˆ—ä¿¡æ¯ï¼ŒTransformeræ¨¡å‹å¼•å…¥äº†ä½ç½®ç¼–ç å»ä¿æŒè¾“å…¥åºåˆ—å…ƒç´ çš„ä½ç½®ã€‚

å‡è®¾è¾“å…¥åºåˆ—çš„åµŒå…¥è¡¨ç¤º $X\in \mathbb{R}^{l\times d}$, åºåˆ—é•¿åº¦ä¸º$l$åµŒå…¥å‘é‡ç»´åº¦ä¸º$d$ï¼Œåˆ™å…¶ä½ç½®ç¼–ç ä¸º$P \in \mathbb{R}^{l\times d}$ ï¼Œè¾“å‡ºçš„å‘é‡å°±æ˜¯äºŒè€…ç›¸åŠ  $X + P$ã€‚

ä½ç½®ç¼–ç æ˜¯ä¸€ä¸ªäºŒç»´çš„çŸ©é˜µï¼Œiå¯¹åº”ç€åºåˆ—ä¸­çš„é¡ºåºï¼Œjå¯¹åº”å…¶embedding vectorå†…éƒ¨çš„ç»´åº¦ç´¢å¼•ã€‚æˆ‘ä»¬å¯ä»¥é€šè¿‡ä»¥ä¸‹ç­‰å¼è®¡ç®—ä½ç½®ç¼–ç ï¼š

$$
P_{i,2j} = sin(i/10000^{2j/d})
$$


$$
P_{i,2j+1} = cos(i/10000^{2j/d})
$$

$$
for\ i=0,\ldots, l-1\ and\ j=0,\ldots,\lfloor (d-1)/2 \rfloor
$$


![Image Name](https://cdn.kesci.com/upload/image/q5kpe0lu38.png?imageView2/0/w/640/h/640)
### ç¼–ç å™¨

æˆ‘ä»¬å·²ç»æœ‰äº†ç»„æˆTransformerçš„å„ä¸ªæ¨¡å—ï¼Œç°åœ¨æˆ‘ä»¬å¯ä»¥å¼€å§‹æ­å»ºäº†ï¼ç¼–ç å™¨åŒ…å«ä¸€ä¸ªå¤šå¤´æ³¨æ„åŠ›å±‚ï¼Œä¸€ä¸ªposition-wise FFNï¼Œå’Œä¸¤ä¸ª Add and Normå±‚ã€‚å¯¹äºattentionæ¨¡å‹ä»¥åŠFFNæ¨¡å‹ï¼Œæˆ‘ä»¬çš„è¾“å‡ºç»´åº¦éƒ½æ˜¯ä¸embeddingç»´åº¦ä¸€è‡´çš„ï¼Œè¿™ä¹Ÿæ˜¯ç”±äºæ®‹å·®è¿æ¥å¤©ç”Ÿçš„ç‰¹æ€§å¯¼è‡´çš„ï¼Œå› ä¸ºæˆ‘ä»¬è¦å°†å‰ä¸€å±‚çš„è¾“å‡ºä¸åŸå§‹è¾“å…¥ç›¸åŠ å¹¶å½’ä¸€åŒ–ã€‚


```python
class EncoderBlock(nn.Module):
    def __init__(self, embedding_size, ffn_hidden_size, num_heads,
                 dropout, **kwargs):
        super(EncoderBlock, self).__init__(**kwargs)
        self.attention = MultiHeadAttention(embedding_size, embedding_size, num_heads, dropout)
        self.addnorm_1 = AddNorm(embedding_size, dropout)
        self.ffn = PositionWiseFFN(embedding_size, ffn_hidden_size, embedding_size)
        self.addnorm_2 = AddNorm(embedding_size, dropout)

    def forward(self, X, valid_length):
        Y = self.addnorm_1(X, self.attention(X, X, X, valid_length))
        return self.addnorm_2(Y, self.ffn(Y))
    
```

```python
# batch_size = 2, seq_len = 100, embedding_size = 24
# ffn_hidden_size = 48, num_head = 8, dropout = 0.5

X = torch.ones((2, 100, 24))
encoder_blk = EncoderBlock(24, 48, 8, 0.5)
encoder_blk(X, valid_length).shape
```

ç°åœ¨æˆ‘ä»¬æ¥å®ç°æ•´ä¸ªTransformer ç¼–ç å™¨æ¨¡å‹ï¼Œæ•´ä¸ªç¼–ç å™¨ç”±nä¸ªåˆšåˆšå®šä¹‰çš„Encoder Blockå †å è€Œæˆï¼Œå› ä¸ºæ®‹å·®è¿æ¥çš„ç¼˜æ•…ï¼Œä¸­é—´çŠ¶æ€çš„ç»´åº¦å§‹ç»ˆä¸åµŒå…¥å‘é‡çš„ç»´åº¦dä¸€è‡´ï¼›åŒæ—¶æ³¨æ„åˆ°æˆ‘ä»¬æŠŠåµŒå…¥å‘é‡ä¹˜ä»¥ $\sqrt{d}$ ä»¥é˜²æ­¢å…¶å€¼è¿‡å°ã€‚
```python
class TransformerEncoder(d2l.Encoder):
    def __init__(self, vocab_size, embedding_size, ffn_hidden_size,
                 num_heads, num_layers, dropout, **kwargs):
        super(TransformerEncoder, self).__init__(**kwargs)
        self.embedding_size = embedding_size
        self.embed = nn.Embedding(vocab_size, embedding_size)
        self.pos_encoding = PositionalEncoding(embedding_size, dropout)
        self.blks = nn.ModuleList()
        for i in range(num_layers):
            self.blks.append(
                EncoderBlock(embedding_size, ffn_hidden_size,
                             num_heads, dropout))

    def forward(self, X, valid_length, *args):
        X = self.pos_encoding(self.embed(X) * math.sqrt(self.embedding_size))
        for blk in self.blks:
            X = blk(X, valid_length)
        return X
```
### è§£ç å™¨

Transformer æ¨¡å‹çš„è§£ç å™¨ä¸ç¼–ç å™¨ç»“æ„ç±»ä¼¼ï¼Œç„¶è€Œï¼Œé™¤äº†ä¹‹å‰ä»‹ç»çš„å‡ ä¸ªæ¨¡å—ä¹‹å¤–ï¼Œç¼–ç å™¨éƒ¨åˆ†æœ‰å¦ä¸€ä¸ªå­æ¨¡å—ã€‚è¯¥æ¨¡å—ä¹Ÿæ˜¯å¤šå¤´æ³¨æ„åŠ›å±‚ï¼Œæ¥å—ç¼–ç å™¨çš„è¾“å‡ºä½œä¸ºkeyå’Œvalueï¼Œdecoderçš„çŠ¶æ€ä½œä¸ºqueryã€‚ä¸ç¼–ç å™¨éƒ¨åˆ†ç›¸ç±»ä¼¼ï¼Œè§£ç å™¨åŒæ ·æ˜¯ä½¿ç”¨äº†add and normæœºåˆ¶ï¼Œç”¨æ®‹å·®å’Œå±‚å½’ä¸€åŒ–å°†å„ä¸ªå­å±‚çš„è¾“å‡ºç›¸è¿ã€‚

ä»”ç»†æ¥è®²ï¼Œåœ¨ç¬¬tä¸ªæ—¶é—´æ­¥ï¼Œå½“å‰è¾“å…¥$x_t$æ˜¯queryï¼Œé‚£ä¹ˆself attentionæ¥å—äº†ç¬¬tæ­¥ä»¥åŠå‰t-1æ­¥çš„æ‰€æœ‰è¾“å…¥$x_1,\ldots, x_{t-1}$ã€‚åœ¨è®­ç»ƒæ—¶ï¼Œç”±äºç¬¬tä½ç½®çš„è¾“å…¥å¯ä»¥è§‚æµ‹åˆ°å…¨éƒ¨çš„åºåˆ—ï¼Œè¿™ä¸é¢„æµ‹é˜¶æ®µçš„æƒ…å½¢é¡¹çŸ›ç›¾ï¼Œæ‰€ä»¥æˆ‘ä»¬è¦é€šè¿‡å°†ç¬¬tä¸ªæ—¶é—´æ­¥æ‰€å¯¹åº”çš„å¯è§‚æµ‹é•¿åº¦è®¾ç½®ä¸ºtï¼Œä»¥æ¶ˆé™¤ä¸éœ€è¦çœ‹åˆ°çš„æœªæ¥çš„ä¿¡æ¯ã€‚


![Image Name](https://cdn.kesci.com/upload/image/q5kpefhcyg.png?imageView2/0/w/800/h/800)

```python
class DecoderBlock(nn.Module):
    def __init__(self, embedding_size, ffn_hidden_size, num_heads,dropout,i,**kwargs):
        super(DecoderBlock, self).__init__(**kwargs)
        self.i = i
        self.attention_1 = MultiHeadAttention(embedding_size, embedding_size, num_heads, dropout)
        self.addnorm_1 = AddNorm(embedding_size, dropout)
        self.attention_2 = MultiHeadAttention(embedding_size, embedding_size, num_heads, dropout)
        self.addnorm_2 = AddNorm(embedding_size, dropout)
        self.ffn = PositionWiseFFN(embedding_size, ffn_hidden_size, embedding_size)
        self.addnorm_3 = AddNorm(embedding_size, dropout)
    
    def forward(self, X, state):
        enc_outputs, enc_valid_length = state[0], state[1]
        
        # state[2][self.i] stores all the previous t-1 query state of layer-i
        # len(state[2]) = num_layers
        
        # If training:
        #     state[2] is useless.
        # If predicting:
        #     In the t-th timestep:
        #         state[2][self.i].shape = (batch_size, t-1, hidden_size)
        # Demo:
        # love dogs ! [EOS]
        #  |    |   |   |
        #   Transformer 
        #    Decoder
        #  |   |   |   |
        #  I love dogs !
        
        if state[2][self.i] is None:
            key_values = X
        else:
            # shape of key_values = (batch_size, t, hidden_size)
            key_values = torch.cat((state[2][self.i], X), dim=1) 
        state[2][self.i] = key_values
        
        if self.training:
            batch_size, seq_len, _ = X.shape
            # Shape: (batch_size, seq_len), the values in the j-th column are j+1
            valid_length = torch.FloatTensor(np.tile(np.arange(1, seq_len+1), (batch_size, 1))) 
            valid_length = valid_length.to(X.device)
        else:
            valid_length = None

        X2 = self.attention_1(X, key_values, key_values, valid_length)
        Y = self.addnorm_1(X, X2)
        Y2 = self.attention_2(Y, enc_outputs, enc_outputs, enc_valid_length)
        Z = self.addnorm_2(Y, Y2)
        return self.addnorm_3(Z, self.ffn(Z)), state
```

[åŠ é€Ÿç½‘ç»œæ”¶æ•›â€”â€”BNã€LNã€WNä¸selu]: https://www.cnblogs.com/jins-note/p/10119168.html

